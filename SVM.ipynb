{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import relevant modules \n",
    "#import relevant libraries \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('framingham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>30.30</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>33.11</td>\n",
       "      <td>60.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>21.68</td>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>141.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>26.36</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>23.61</td>\n",
       "      <td>93.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "5     0   43        2.0              0         0.0     0.0                0   \n",
       "6     0   63        1.0              0         0.0     0.0                0   \n",
       "7     0   45        2.0              1        20.0     0.0                0   \n",
       "8     1   52        1.0              0         0.0     0.0                0   \n",
       "9     1   43        1.0              1        30.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "5             1         0    228.0  180.0  110.0  30.30       77.0     99.0   \n",
       "6             0         0    205.0  138.0   71.0  33.11       60.0     85.0   \n",
       "7             0         0    313.0  100.0   71.0  21.68       79.0     78.0   \n",
       "8             1         0    260.0  141.5   89.0  26.36       76.0     79.0   \n",
       "9             1         0    225.0  162.0  107.0  23.61       93.0     88.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  \n",
       "5           0  \n",
       "6           1  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Selecting features - dropping uninteresting columns'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Selecting features - dropping uninteresting columns'''\n",
    "\n",
    "def chose_features(dataset, features=dataset.columns, n_features = -1, v=1, vv =0):\n",
    "    '''Return reduced dataset with only chosen columns\n",
    "    - dataset: pandas dataframe of dataset to have columns chosen\n",
    "    - features (optional, default = all features): list of strings matching features to keep\n",
    "    - n_features (optional) - if specified, the top n features from the scaled list is chosen: \n",
    "    ['glucose', 'age', 'totChol', 'cigsPerDay', 'diaBP', 'prevalentHyp',\n",
    "        'diabetes', 'BPMeds', 'male', 'BMI', 'prevalentStroke',\n",
    "        'education', 'heartRate', 'currentSmoker'],\n",
    "    - v (optional) - Verbose (default 1) int 0 or 1. Print no. of features kept and lost \n",
    "    - vv (optional) - Very verbose (default 0) int 0 or 1. Print list of chosen and rejected features\n",
    "    '''\n",
    "                \n",
    "    print('Now selecting chosen features....')\n",
    "    \n",
    "    if n_features != -1:\n",
    "        if n_features > len(dataset.columns):\n",
    "            print('WARNING: chose_features has an error: n_features must be less than no. columns')\n",
    "            return(-1)\n",
    "        else:\n",
    "            ordered_f = ['TenYearCHD','glucose', 'age', 'totChol', 'cigsPerDay', 'diaBP', 'prevalentHyp',\n",
    "            'diabetes', 'BPMeds', 'male', 'BMI', 'sysBP','prevalentStroke',\n",
    "            'education', 'heartRate', 'currentSmoker']\n",
    "            features = ordered_f[0:n_features]\n",
    "\n",
    "    if v == 1: \n",
    "        print('\\t * Number of features: ', len(features))\n",
    "        print('\\t * Number of dropped features: ', len(dataset.columns) - len(features))\n",
    "        \n",
    "    if vv == 1:\n",
    "        print('\\t * Chosen features: ', features)\n",
    "        print('\\t * Dropped features: ',[col for col in dataset.columns if col not in features])\n",
    "    print('')\n",
    "    \n",
    "    return dataset.copy()[features] #reduced dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dealing with missing values'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Dealing with missing values'''\n",
    "\n",
    "#Method 1: Drop missing values\n",
    "def drop_missing(dataset):\n",
    "    '''Drop rows with any missing values and return dataset with dropped rows. Prints number and percentage of rows dropped\n",
    "    - Dataset: pandas Dataframe\n",
    "    '''\n",
    "    print('Now dropping rows with missing values....')\n",
    "    dataset2 = dataset.copy().dropna().reset_index(drop=True)\n",
    "    lost = len(dataset) - len(dataset2)\n",
    "    print('\\t * Dropped {} rows {:.1f}%. {} rows remaining\\n'.format(lost,lost/len(dataset)*100,len(dataset2)))\n",
    "    return dataset2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_normalize(dataset):\n",
    "    '''\n",
    "    Normalise all features in a dataframe between -1 and 1 and return normalised dataframe.\n",
    "    This is one method of feature scaling that may aid the performace of some ML algorithms\n",
    "    Normalisation: (feature - mean)/range\n",
    "    '''\n",
    "\n",
    "    for feature in dataset:\n",
    "        \n",
    "        fmean = np.mean(dataset[feature])\n",
    "        frange = np.amax(dataset[feature]) - np.amin(dataset[feature])\n",
    "\n",
    "        #Vector Subtraction\n",
    "        dataset[feature] = dataset[feature] - fmean\n",
    "        #Vector Division\n",
    "        dataset[feature] = dataset[feature] / frange\n",
    "\n",
    "    return dataset\n",
    "\n",
    "##e.g.\n",
    "#dataset_n = mean_normalize(dataset.copy())\n",
    "#dataset_n.head()\n",
    "\n",
    "##I then found there were some build in normalisation/ scaling modules in sklearn.preprocessing so tried some of these\n",
    "\n",
    "\n",
    "def scale_data(data, method='std'):\n",
    "    '''Return dataset scaled by MinMaxScalar or StandardScalar methods from sklearn.preprocessing\n",
    "    - data: pandas dataframe of data to be scaled\n",
    "    - method (optional): str of either 'minmax' for MinMaxScalar or 'std' for StandardScaler (default arg)\n",
    "    '''\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "    if method == 'minmax':\n",
    "        scaler_minmax = preprocessing.MinMaxScaler((0,1))\n",
    "        return pd.DataFrame(scaler_minmax.fit_transform(data.copy()),columns=data.columns) \n",
    "    \n",
    "    elif method == 'std':\n",
    "        scaler_std = preprocessing.StandardScaler() #with_std=False\n",
    "        return pd.DataFrame(scaler_std.fit_transform(dataset.copy()),columns=dataset.columns)\n",
    "    \n",
    "    else:\n",
    "        print('\\nscale_data encountered a failure!!\\n')\n",
    "        return(-1)\n",
    "\n",
    "##e.g.\n",
    "##scale_data(dataset).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(dataset,dep_var='TenYearCHD', test_size = 0.2, v = 1):\n",
    "    '''Split the dataset, return X_train, X_test, y_train, y_test as Pandas Dataframes\n",
    "    - dataset: Pandas Dataframe. Data to split into training and test data\n",
    "    - dep_var (optional, default = 'TenYearCHD'): string. Name of column to be dependant variable\n",
    "    - test_size (optional, default = 0.2): float (0.0-1.0). Proportion of total data to make up test set.\n",
    "    '''\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    y = dataset[dep_var]\n",
    "    X = dataset.drop([dep_var], axis = 1)\n",
    "    if v == 1: \n",
    "        print('Splitting data set into {}% training, {}% test dataset....'.format(100*(1-test_size),100*test_size))\n",
    "        \n",
    "    return train_test_split(X, y, test_size = test_size, random_state=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating SVM function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM(X_train, X_test, y_train, y_test, v=0):\n",
    "    '''Do support vector mechanism fitting and print information about the success of the fitting\n",
    "    - X_train: Dataframe x training set\n",
    "    - y_train: Dataframe y training set\n",
    "    - X_test: Dataframe x test set\n",
    "    - y_test: Dataframe y test set\n",
    "    - v (optional, default = 0): int (0 or 1) verbose\n",
    "    '''\n",
    "    from sklearn.SVC import SVC\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "    \n",
    "    print('\\nCalculating Support vector machine ..\\n')\n",
    "    SVM = SVC(n_neighbors=10)\n",
    "    KN.fit(X_train, y_train) \n",
    "    y_pred = KN.predict(X_test)\n",
    "    \n",
    "    if v == 1: \n",
    "        print(k_neighbors)\n",
    "        print('Confusion Matrix:')\n",
    "        cm=confusion_matrix(y_test,y_pred)\n",
    "        conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "        sn.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")\n",
    "    \n",
    "        print('Accuracy: {:.2f}%'.format(accuracy_score(y_test,y_pred)*100))\n",
    "\n",
    "        print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    return accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
