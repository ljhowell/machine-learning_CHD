{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing\n",
    "----------\n",
    "The following code contains a series of pre-processing functions that can be used to greatly increase speed of improvement of any ML algorythm.\n",
    "\n",
    "* Selecting features\n",
    "* Dealing with missing values\n",
    "* Dealing with outliers\n",
    "* Feature scaling \n",
    "* Splitting dataset\n",
    "\n",
    "Select features that are input into model. These could be chosen based on what are considered to be the most important features (from Eleanor Barr or my feature importance functions.)\n",
    "\n",
    "This notebook steps through how to: \n",
    "1. Import the preprocessing functions from preprocessing_ml.py\n",
    "2. Use the functions to preprocess data\n",
    "3. How to apply a ML algorithm (Linear Regression) to the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant modules \n",
    "#import relevant libraries \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the dataset \n",
    "dataset = pd.read_csv('framingham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#This is required to accept any changes to the module by forcing notebook to re-read the file \n",
    "#if any changes are made to the module while notebook is running\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take a look at the content of the module:\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'''This is the preprocessing module created by Lewis Howell for the Exeter NatSci Machine Learning Group. 30/10/19\n",
      "The module contains functions for feature selection, dealing with missing values, feature scaling \n",
      "and splitting dataset into test and training sets.\n",
      "\t- chose_features\n",
      "\t- drop_missing\n",
      "\t- impute_missing\n",
      "\t- scale_data\n",
      "\t- split_data\n",
      "'''\n",
      "\n",
      "print(\"Importing the preprocessing module for the Exeter NatSci Machine Learning Group.....\")\n",
      "\n",
      "\n",
      "def chose_features(dataset, features=[], n_features = -1, v=1, vv =0):\n",
      "    '''Return reduced dataset with only chosen columns\n",
      "    - dataset: pandas dataframe of dataset to have columns chosen\n",
      "    - features (optional, default = all features): list of strings matching features to keep\n",
      "    - n_features (optional) - if specified, the top n features from the scaled list is chosen: \n",
      "    ['glucose', 'age', 'totChol', 'cigsPerDay', 'diaBP', 'prevalentHyp',\n",
      "        'diabetes', 'BPMeds', 'male', 'BMI', 'prevalentStroke',\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "#read the preprocessing file to check it is there and looks right\n",
    "\n",
    "head -20 preprocessing_ml.py # Print head of .py file to check if the file can be found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the preprocessing module for the Exeter NatSci Machine Learning Group.....\n",
      "Successfully imported the preprocessing module\n",
      "Now selecting chosen features....\n",
      "\t * Number of features:  15 (and \"10YearCHD\")\n",
      "\t * Number of dropped features:  0\n",
      "\n",
      "Now dropping rows with missing values....\n",
      "\t * Dropped 582 rows 13.7%. 3658 rows remaining\n",
      "\n",
      "Scaling data....\n",
      "\t * Using standard scaling\n",
      "\n",
      "Splitting data set into training and test sets....\n",
      "\t * 80.0% data in training set\n",
      "\t * 20.0% data in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lewma\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\lewma\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#TL;DR\n",
    "# You can use the functions to make the preprocessing VERY easy: #e.g. Process data in 1 line:\n",
    "from preprocessing_ml import *\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(scale_data(drop_missing(chose_features(dataset))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module preprocessing_ml:\n",
      "\n",
      "NAME\n",
      "    preprocessing_ml\n",
      "\n",
      "DESCRIPTION\n",
      "    This is the preprocessing module created by Lewis Howell for the Exeter NatSci Machine Learning Group. 30/10/19\n",
      "    The module contains functions for feature selection, dealing with missing values, feature scaling \n",
      "    and splitting dataset into test and training sets.\n",
      "            - chose_features\n",
      "            - drop_missing\n",
      "            - impute_missing\n",
      "            - scale_data\n",
      "            - split_data\n",
      "\n",
      "FUNCTIONS\n",
      "    chose_features(dataset, features=[], n_features=-1, v=1, vv=0)\n",
      "        Return reduced dataset with only chosen columns\n",
      "        - dataset: pandas dataframe of dataset to have columns chosen\n",
      "        - features (optional, default = all features): list of strings matching features to keep\n",
      "        - n_features (optional) - if specified, the top n features from the scaled list is chosen: \n",
      "        ['glucose', 'age', 'totChol', 'cigsPerDay', 'diaBP', 'prevalentHyp',\n",
      "            'diabetes', 'BPMeds', 'male', 'BMI', 'prevalentStroke',\n",
      "            'education', 'heartRate', 'currentSmoker'],\n",
      "        - v (optional) - Verbose (default 1) int 0 or 1. Print no. of features kept and lost \n",
      "        - vv (optional) - Very verbose (default 0) int 0 or 1. Print list of chosen and rejected features\n",
      "    \n",
      "    drop_missing(dataset)\n",
      "        Drop rows with any missing values and return dataset with dropped rows. Prints number and percentage of rows dropped\n",
      "        - Dataset: pandas Dataframe\n",
      "    \n",
      "    impute_missing(dataset, strategy='median', v=1, vv=0)\n",
      "        Imputation - alternative to removing missing values.\n",
      "        Fill all missing with column average (median or mean)\n",
      "        dataset - Pandas Dataframe to be imputed\n",
      "        strategy - str (optional) 'median' (default) or 'mean' to fill missing values with\n",
      "        - v (optional) - Verbose (default 1) int 0 or 1. Print no. of missing and imputed values  \n",
      "        - vv (optional) - Very verbose (default 0) int 0 or 1. Print list of imputed features with counts and replaced value\n",
      "    \n",
      "    scale_data(data, method='standard', v=1)\n",
      "        Return dataset scaled by MinMaxScalar or StandardScalar methods from sklearn.preprocessing\n",
      "        - data: pandas dataframe of data to be scaled\n",
      "        - method (optional): str of either 'minmax' for MinMaxScalar or 'std' for StandardScaler (default arg)\n",
      "        - v (optiona -default = 1): Verbose\n",
      "    \n",
      "    split_data(dataset, dep_var='TenYearCHD', test_size=0.2, v=1)\n",
      "        Split the dataset, return X_train, X_test, y_train, y_test as Pandas Dataframes\n",
      "        - dataset: Pandas Dataframe. Data to split into training and test data\n",
      "        - dep_var (optional, default = 'TenYearCHD'): string. Name of column to be dependant variable\n",
      "        - test_size (optional, default = 0.2): float (0.0-1.0). Proportion of total data to make up test set.\n",
      "        Returns 4 datasets in order: X_train, X_test, y_train, y_test\n",
      "\n",
      "FILE\n",
      "    c:\\users\\lewma\\onedrive\\documents\\machine-learning_chd\\preprocessing_ml.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Try to import the contents of the local module preprocessing_ml.py file\n",
    "import preprocessing_ml as prep\n",
    "\n",
    "help(prep) #Print the help. Shows the functions in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting columns\n",
    "-------------\n",
    "* n_features from chi squ importance\n",
    "* features from custom list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the preprocessing module for the Exeter NatSci Machine Learning Group.....\n",
      "Successfully imported the preprocessing module\n",
      "Help on function chose_features in module preprocessing_ml:\n",
      "\n",
      "chose_features(dataset, features=[], n_features=-1, v=1, vv=0)\n",
      "    Return reduced dataset with only chosen columns\n",
      "    - dataset: pandas dataframe of dataset to have columns chosen\n",
      "    - features (optional, default = all features): list of strings matching features to keep\n",
      "    - n_features (optional) - if specified, the top n features from the scaled list is chosen: \n",
      "    ['glucose', 'age', 'totChol', 'cigsPerDay', 'diaBP', 'prevalentHyp',\n",
      "        'diabetes', 'BPMeds', 'male', 'BMI', 'prevalentStroke',\n",
      "        'education', 'heartRate', 'currentSmoker'],\n",
      "    - v (optional) - Verbose (default 1) int 0 or 1. Print no. of features kept and lost \n",
      "    - vv (optional) - Very verbose (default 0) int 0 or 1. Print list of chosen and rejected features\n",
      "\n",
      "Now selecting chosen features....\n",
      "\t * Number of features:  10 (and \"10YearCHD\")\n",
      "\t * Number of dropped features:  5\n",
      "\t * Chosen features:  ['TenYearCHD', 'sysBP', 'glucose', 'age', 'totChol', 'cigsPerDay', 'diaBP', 'prevalentHyp', 'diabetes', 'BPMeds', 'male']\n",
      "\t * Dropped features:  ['education', 'currentSmoker', 'prevalentStroke', 'BMI', 'heartRate']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TenYearCHD</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>glucose</th>\n",
       "      <th>age</th>\n",
       "      <th>totChol</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>39</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>46</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TenYearCHD  sysBP  glucose  age  totChol  cigsPerDay  diaBP  prevalentHyp  \\\n",
       "0           0  106.0     77.0   39    195.0         0.0   70.0             0   \n",
       "1           0  121.0     76.0   46    250.0         0.0   81.0             0   \n",
       "\n",
       "   diabetes  BPMeds  male  \n",
       "0         0     0.0     1  \n",
       "1         0     0.0     0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example for how to use:\n",
    "\n",
    "#1. Feature selection:\n",
    "help(prep.chose_features) #print help to see usage of module \n",
    "\n",
    "#features_list = ['TenYearCHD', sysBP', 'age', 'cigsPerDay', 'totChol']\n",
    "#print(prep.chose_features(dataset, features=features_list,vv=1))\n",
    "\n",
    "d2 = prep.chose_features(dataset, n_features=10,vv=1)\n",
    "d2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing values\n",
    "-------------\n",
    "* Dropping missing values\n",
    "* Imputation\n",
    "    * Mean or median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function drop_missing in module preprocessing_ml:\n",
      "\n",
      "drop_missing(dataset)\n",
      "    Drop rows with any missing values and return dataset with dropped rows. Prints number and percentage of rows dropped\n",
      "    - Dataset: pandas Dataframe\n",
      "\n",
      "Now dropping rows with missing values....\n",
      "\t * Dropped 474 rows 11.2%. 3766 rows remaining\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TenYearCHD</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>glucose</th>\n",
       "      <th>age</th>\n",
       "      <th>totChol</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>39</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>46</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>48</td>\n",
       "      <td>245.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61</td>\n",
       "      <td>225.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>46</td>\n",
       "      <td>285.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TenYearCHD  sysBP  glucose  age  totChol  cigsPerDay  diaBP  prevalentHyp  \\\n",
       "0           0  106.0     77.0   39    195.0         0.0   70.0             0   \n",
       "1           0  121.0     76.0   46    250.0         0.0   81.0             0   \n",
       "2           0  127.5     70.0   48    245.0        20.0   80.0             0   \n",
       "3           1  150.0    103.0   61    225.0        30.0   95.0             1   \n",
       "4           0  130.0     85.0   46    285.0        23.0   84.0             0   \n",
       "\n",
       "   diabetes  BPMeds  male  \n",
       "0         0     0.0     1  \n",
       "1         0     0.0     0  \n",
       "2         0     0.0     1  \n",
       "3         0     0.0     0  \n",
       "4         0     0.0     0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Dealing with missing values: Dropping\n",
    "\n",
    "help(prep.drop_missing)\n",
    "\n",
    "d3 = prep.drop_missing(d2)\n",
    "d3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function impute_missing in module preprocessing_ml:\n",
      "\n",
      "impute_missing(dataset, strategy='median', v=1, vv=0)\n",
      "    Imputation - alternative to removing missing values.\n",
      "    Fill all missing with column average (median or mean)\n",
      "    dataset - Pandas Dataframe to be imputed\n",
      "    strategy - str (optional) 'median' (default) or 'mean' to fill missing values with\n",
      "    - v (optional) - Verbose (default 1) int 0 or 1. Print no. of missing and imputed values  \n",
      "    - vv (optional) - Very verbose (default 0) int 0 or 1. Print list of imputed features with counts and replaced value\n",
      "\n",
      "Imputing missing values with median....\n",
      "\t * Number of missing values:  520\n",
      "\t * Number of imputed values:  520\n",
      "\n",
      "\n",
      "              N_missing  Imputed_value\n",
      "glucose             388           78.0\n",
      "BPMeds               53            0.0\n",
      "totChol              50          234.0\n",
      "cigsPerDay           29            0.0\n",
      "male                  0            0.0\n",
      "diabetes              0            0.0\n",
      "prevalentHyp          0            0.0\n",
      "diaBP                 0           82.0\n",
      "age                   0           49.0\n",
      "sysBP                 0          128.0\n",
      "TenYearCHD            0            0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TenYearCHD</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>glucose</th>\n",
       "      <th>age</th>\n",
       "      <th>totChol</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TenYearCHD  sysBP  glucose   age  totChol  cigsPerDay  diaBP  prevalentHyp  \\\n",
       "0         0.0  106.0     77.0  39.0    195.0         0.0   70.0           0.0   \n",
       "1         0.0  121.0     76.0  46.0    250.0         0.0   81.0           0.0   \n",
       "2         0.0  127.5     70.0  48.0    245.0        20.0   80.0           0.0   \n",
       "3         1.0  150.0    103.0  61.0    225.0        30.0   95.0           1.0   \n",
       "4         0.0  130.0     85.0  46.0    285.0        23.0   84.0           0.0   \n",
       "\n",
       "   diabetes  BPMeds  male  \n",
       "0       0.0     0.0   1.0  \n",
       "1       0.0     0.0   0.0  \n",
       "2       0.0     0.0   1.0  \n",
       "3       0.0     0.0   0.0  \n",
       "4       0.0     0.0   0.0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.1 Imputation as an alternative to dropping missing vals\n",
    "help(impute_missing)\n",
    "d3_2 = prep.impute_missing(d2,strategy='median',vv=1)\n",
    "d3_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function scale_data in module preprocessing_ml:\n",
      "\n",
      "scale_data(data, method='standard', v=1)\n",
      "    Return dataset scaled by MinMaxScalar or StandardScalar methods from sklearn.preprocessing\n",
      "    - data: pandas dataframe of data to be scaled\n",
      "    - method (optional): str of either 'minmax' for MinMaxScalar or 'std' for StandardScaler (default arg)\n",
      "    - v (optiona -default = 1): Verbose\n",
      "\n",
      "Scaling data....\n",
      "\t * Using standard scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lewma\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\lewma\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TenYearCHD</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>glucose</th>\n",
       "      <th>age</th>\n",
       "      <th>totChol</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.426669</td>\n",
       "      <td>-1.193478</td>\n",
       "      <td>-0.203953</td>\n",
       "      <td>-1.232568</td>\n",
       "      <td>-0.938737</td>\n",
       "      <td>-0.755367</td>\n",
       "      <td>-1.083114</td>\n",
       "      <td>-0.673835</td>\n",
       "      <td>-0.167687</td>\n",
       "      <td>-0.17668</td>\n",
       "      <td>1.116699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.426669</td>\n",
       "      <td>-0.515134</td>\n",
       "      <td>-0.245451</td>\n",
       "      <td>-0.417595</td>\n",
       "      <td>0.294170</td>\n",
       "      <td>-0.755367</td>\n",
       "      <td>-0.161456</td>\n",
       "      <td>-0.673835</td>\n",
       "      <td>-0.167687</td>\n",
       "      <td>-0.17668</td>\n",
       "      <td>-0.895496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.426669</td>\n",
       "      <td>-0.221185</td>\n",
       "      <td>-0.494439</td>\n",
       "      <td>-0.184746</td>\n",
       "      <td>0.182088</td>\n",
       "      <td>0.923276</td>\n",
       "      <td>-0.245243</td>\n",
       "      <td>-0.673835</td>\n",
       "      <td>-0.167687</td>\n",
       "      <td>-0.17668</td>\n",
       "      <td>1.116699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.343737</td>\n",
       "      <td>0.796330</td>\n",
       "      <td>0.874995</td>\n",
       "      <td>1.328775</td>\n",
       "      <td>-0.266242</td>\n",
       "      <td>1.762598</td>\n",
       "      <td>1.011563</td>\n",
       "      <td>1.484042</td>\n",
       "      <td>-0.167687</td>\n",
       "      <td>-0.17668</td>\n",
       "      <td>-0.895496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.426669</td>\n",
       "      <td>-0.108128</td>\n",
       "      <td>0.128031</td>\n",
       "      <td>-0.417595</td>\n",
       "      <td>1.078748</td>\n",
       "      <td>1.175073</td>\n",
       "      <td>0.089905</td>\n",
       "      <td>-0.673835</td>\n",
       "      <td>-0.167687</td>\n",
       "      <td>-0.17668</td>\n",
       "      <td>-0.895496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TenYearCHD     sysBP   glucose       age   totChol  cigsPerDay     diaBP  \\\n",
       "0   -0.426669 -1.193478 -0.203953 -1.232568 -0.938737   -0.755367 -1.083114   \n",
       "1   -0.426669 -0.515134 -0.245451 -0.417595  0.294170   -0.755367 -0.161456   \n",
       "2   -0.426669 -0.221185 -0.494439 -0.184746  0.182088    0.923276 -0.245243   \n",
       "3    2.343737  0.796330  0.874995  1.328775 -0.266242    1.762598  1.011563   \n",
       "4   -0.426669 -0.108128  0.128031 -0.417595  1.078748    1.175073  0.089905   \n",
       "\n",
       "   prevalentHyp  diabetes   BPMeds      male  \n",
       "0     -0.673835 -0.167687 -0.17668  1.116699  \n",
       "1     -0.673835 -0.167687 -0.17668 -0.895496  \n",
       "2     -0.673835 -0.167687 -0.17668  1.116699  \n",
       "3      1.484042 -0.167687 -0.17668 -0.895496  \n",
       "4     -0.673835 -0.167687 -0.17668 -0.895496  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Scaling\n",
    "help(scale_data)\n",
    "\n",
    "d4 = prep.scale_data(d3,method='standard')\n",
    "d4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function split_data in module preprocessing_ml:\n",
      "\n",
      "split_data(dataset, dep_var='TenYearCHD', test_size=0.2, v=1)\n",
      "    Split the dataset, return X_train, X_test, y_train, y_test as Pandas Dataframes\n",
      "    - dataset: Pandas Dataframe. Data to split into training and test data\n",
      "    - dep_var (optional, default = 'TenYearCHD'): string. Name of column to be dependant variable\n",
      "    - test_size (optional, default = 0.2): float (0.0-1.0). Proportion of total data to make up test set.\n",
      "    Returns 4 datasets in order: X_train, X_test, y_train, y_test\n",
      "\n",
      "\n",
      "Splitting data set into training and test sets....\n",
      "\t * 80.0% data in training set\n",
      "\t * 20.0% data in test set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sysBP</th>\n",
       "      <th>glucose</th>\n",
       "      <th>age</th>\n",
       "      <th>totChol</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>-0.967363</td>\n",
       "      <td>0.128031</td>\n",
       "      <td>-0.534020</td>\n",
       "      <td>-0.938737</td>\n",
       "      <td>-0.083910</td>\n",
       "      <td>-0.329030</td>\n",
       "      <td>-0.673835</td>\n",
       "      <td>-0.167687</td>\n",
       "      <td>-0.17668</td>\n",
       "      <td>-0.895496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.469911</td>\n",
       "      <td>-0.162455</td>\n",
       "      <td>-1.348993</td>\n",
       "      <td>-0.938737</td>\n",
       "      <td>-0.335706</td>\n",
       "      <td>0.131799</td>\n",
       "      <td>-0.673835</td>\n",
       "      <td>-0.167687</td>\n",
       "      <td>-0.17668</td>\n",
       "      <td>-0.895496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>1.632954</td>\n",
       "      <td>-0.203953</td>\n",
       "      <td>0.164528</td>\n",
       "      <td>-0.154160</td>\n",
       "      <td>-0.755367</td>\n",
       "      <td>1.179137</td>\n",
       "      <td>1.484042</td>\n",
       "      <td>-0.167687</td>\n",
       "      <td>-0.17668</td>\n",
       "      <td>-0.895496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>-0.221185</td>\n",
       "      <td>-0.079459</td>\n",
       "      <td>1.445199</td>\n",
       "      <td>-0.669739</td>\n",
       "      <td>-0.755367</td>\n",
       "      <td>-0.664178</td>\n",
       "      <td>-0.673835</td>\n",
       "      <td>-0.167687</td>\n",
       "      <td>-0.17668</td>\n",
       "      <td>-0.895496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>-0.786472</td>\n",
       "      <td>-0.577435</td>\n",
       "      <td>0.280953</td>\n",
       "      <td>-0.109327</td>\n",
       "      <td>0.923276</td>\n",
       "      <td>-0.245243</td>\n",
       "      <td>-0.673835</td>\n",
       "      <td>-0.167687</td>\n",
       "      <td>-0.17668</td>\n",
       "      <td>-0.895496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sysBP   glucose       age   totChol  cigsPerDay     diaBP  \\\n",
       "1571 -0.967363  0.128031 -0.534020 -0.938737   -0.083910 -0.329030   \n",
       "17   -0.469911 -0.162455 -1.348993 -0.938737   -0.335706  0.131799   \n",
       "3039  1.632954 -0.203953  0.164528 -0.154160   -0.755367  1.179137   \n",
       "3686 -0.221185 -0.079459  1.445199 -0.669739   -0.755367 -0.664178   \n",
       "1936 -0.786472 -0.577435  0.280953 -0.109327    0.923276 -0.245243   \n",
       "\n",
       "      prevalentHyp  diabetes   BPMeds      male  \n",
       "1571     -0.673835 -0.167687 -0.17668 -0.895496  \n",
       "17       -0.673835 -0.167687 -0.17668 -0.895496  \n",
       "3039      1.484042 -0.167687 -0.17668 -0.895496  \n",
       "3686     -0.673835 -0.167687 -0.17668 -0.895496  \n",
       "1936     -0.673835 -0.167687 -0.17668 -0.895496  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Splitting Data\n",
    "\n",
    "help(prep.split_data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = prep.split_data(d4)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the original functions. FOR REFERENCE ONLY. Any fixes should be made to the preprocessing_ml.py file.\n",
    "\n",
    "You should NOT need to run the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Selecting features - dropping uninteresting columns'''\n",
    "\n",
    "\n",
    "def chose_features(dataset, features=dataset.columns, n_features = -1, v=1, vv =0):\n",
    "    '''Return reduced dataset with only chosen columns\n",
    "    - dataset: pandas dataframe of dataset to have columns chosen\n",
    "    - features (optional, default = all features): list of strings matching features to keep\n",
    "    - n_features (optional) - if specified, the top n features from the scaled list is chosen: \n",
    "    ['glucose', 'age', 'totChol', 'cigsPerDay', 'diaBP', 'prevalentHyp',\n",
    "        'diabetes', 'BPMeds', 'male', 'BMI', 'prevalentStroke',\n",
    "        'education', 'heartRate', 'currentSmoker'],\n",
    "    - v (optional) - Verbose (default 1) int 0 or 1. Print no. of features kept and lost \n",
    "    - vv (optional) - Very verbose (default 0) int 0 or 1. Print list of chosen and rejected features\n",
    "    '''\n",
    "                \n",
    "    print('Now selecting chosen features....')\n",
    "    \n",
    "    if n_features != -1: \n",
    "        if n_features > len(dataset.columns):\n",
    "            print('WARNING: chose_features has an error: n_features must be less than no. columns')\n",
    "            return(-1)\n",
    "        else:\n",
    "            ordered_f = ['TenYearCHD','glucose', 'age', 'totChol', 'cigsPerDay', 'diaBP', 'prevalentHyp',\n",
    "            'diabetes', 'BPMeds', 'male', 'BMI', 'sysBP','prevalentStroke',\n",
    "            'education', 'heartRate', 'currentSmoker']\n",
    "            features = ordered_f[0:n_features]\n",
    "\n",
    "    if v == 1: \n",
    "        print('\\t * Number of features: ', len(features))\n",
    "        print('\\t * Number of dropped features: ', len(dataset.columns) - len(features))\n",
    "        \n",
    "    if vv == 1:\n",
    "        print('\\t * Chosen features: ', features)\n",
    "        print('\\t * Dropped features: ',[col for col in dataset.columns if col not in features])\n",
    "    print('')\n",
    "    \n",
    "    return dataset.copy()[features] #reduced dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''Dealing with missing values'''\n",
    "DONT RUN THIS\n",
    "#Method 1: Drop missing values\n",
    "def drop_missing(dataset):\n",
    "    '''Drop rows with any missing values and return dataset with dropped rows. Prints number and percentage of rows dropped\n",
    "    - Dataset: pandas Dataframe\n",
    "    '''\n",
    "    print('Now dropping rows with missing values....')\n",
    "    dataset2 = dataset.copy().dropna().reset_index(drop=True)\n",
    "    lost = len(dataset) - len(dataset2)\n",
    "    print('\\t * Dropped {} rows {:.1f}%. {} rows remaining\\n'.format(lost,lost/len(dataset)*100,len(dataset2)))\n",
    "    return dataset2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DONT RUN THIS\n",
    "def mean_normalize(dataset):\n",
    "    '''\n",
    "    Normalise all features in a dataframe between -1 and 1 and return normalised dataframe.\n",
    "    This is one method of feature scaling that may aid the performace of some ML algorithms\n",
    "    Normalisation: (feature - mean)/range\n",
    "    '''\n",
    "\n",
    "    for feature in dataset:\n",
    "        \n",
    "        fmean = np.mean(dataset[feature])\n",
    "        frange = np.amax(dataset[feature]) - np.amin(dataset[feature])\n",
    "\n",
    "        #Vector Subtraction\n",
    "        dataset[feature] = dataset[feature] - fmean\n",
    "        #Vector Division\n",
    "        dataset[feature] = dataset[feature] / frange\n",
    "\n",
    "    return dataset\n",
    "\n",
    "##e.g.\n",
    "#dataset_n = mean_normalize(dataset.copy())\n",
    "#dataset_n.head()\n",
    "\n",
    "##I then found there were some build in normalisation/ scaling modules in sklearn.preprocessing so tried some of these\n",
    "\n",
    "\n",
    "def scale_data(data, method='std'):\n",
    "    '''Return dataset scaled by MinMaxScalar or StandardScalar methods from sklearn.preprocessing\n",
    "    - data: pandas dataframe of data to be scaled\n",
    "    - method (optional): str of either 'minmax' for MinMaxScalar or 'std' for StandardScaler (default arg)\n",
    "    '''\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "    if method == 'minmax':\n",
    "        scaler_minmax = preprocessing.MinMaxScaler((0,1))\n",
    "        return pd.DataFrame(scaler_minmax.fit_transform(data.copy()),columns=data.columns) \n",
    "    \n",
    "    elif method == 'std':\n",
    "        scaler_std = preprocessing.StandardScaler() #with_std=False\n",
    "        return pd.DataFrame(scaler_std.fit_transform(dataset.copy()),columns=dataset.columns)\n",
    "    \n",
    "    else:\n",
    "        print('\\nscale_data encountered a failure!!\\n')\n",
    "        return(-1)\n",
    "\n",
    "##e.g.\n",
    "##scale_data(dataset).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DONT RUN THIS\n",
    "def split_data(dataset,dep_var='TenYearCHD', test_size = 0.2, v = 1):\n",
    "    '''Split the dataset, return X_train, X_test, y_train, y_test as Pandas Dataframes\n",
    "    - dataset: Pandas Dataframe. Data to split into training and test data\n",
    "    - dep_var (optional, default = 'TenYearCHD'): string. Name of column to be dependant variable\n",
    "    - test_size (optional, default = 0.2): float (0.0-1.0). Proportion of total data to make up test set.\n",
    "    '''\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    y = dataset[dep_var]\n",
    "    X = dataset.drop([dep_var], axis = 1)\n",
    "    if v == 1: \n",
    "        print('Splitting data set into {}% training, {}% test dataset....'.format(100*(1-test_size),100*test_size))\n",
    "        \n",
    "    return train_test_split(X, y, test_size = test_size, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross - validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation is used to asses the predictive performance of the models and to judge how they will perform outside the sample to a new dataset \n",
    "\n",
    "The main method is the k-fold validation method, which follows the general procedure:\n",
    "1. shuffle dataset randomly\n",
    "2. split dataset into k groups\n",
    "3. For each unique group \n",
    "    - take the group as a hold out or test data set \n",
    "    - take the remaining groups as a training set \n",
    "    - fit a model on the training set and evaluate it on the test set \n",
    "    - retain the evaluation score and discard the model \n",
    "4. Summarize the skill of the model using the sample model evaluation score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, X, Y, cv=3):\n",
    "    from sklearn.model_selection import cross_val_score \n",
    "\n",
    "    print('\\nCrossvalidation score for {} splits:\\n'.format(cv))   \n",
    "    cv_results = cross_val_score(model, X, Y, cv)\n",
    "    print(cv_results)\n",
    "    print(\"Cross validation Accuracy: %0.2f (+/- %0.2f)\" % (cv_results.mean(), cv_results.std() * 2))\n",
    "    \n",
    "\n",
    "#where model_name is replaced by whatever you have defined the model fit as \n",
    "#For example in the K-neighbors section I have defined the model_name as KN. (see k_neighbors function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any further explanation is required about these functions they have been implemented within the k_neighbors notebook or ask Lewis or Ellie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
