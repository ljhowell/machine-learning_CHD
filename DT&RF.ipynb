{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees & Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    }
   ],
   "source": [
    "###Checking which version of python is being used\n",
    "\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Importing the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Importing & checking the data\n",
    "\n",
    "data = pd.read_csv(\"framingham.csv\")\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Representing the data\n",
    "\n",
    "fig = plt.figure(figsize = (15,20));\n",
    "ax = fig.gca();\n",
    "data.hist(ax = ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Checking correlation between data\n",
    "\n",
    "data_corr = data.corr();\n",
    "sns.heatmap(data_corr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['education','glucose'], axis=1);\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Dropping missing data\n",
    "\n",
    "print(data.isna().sum());\n",
    "data = data.dropna();\n",
    "print(data.isna().sum());\n",
    "data.columns;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Spliting features and target variable\n",
    "target = data.iloc[:,-1]\n",
    "features = data.iloc[:,:-1]\n",
    "\n",
    "print(target.head())\n",
    "print(target.shape)\n",
    "print(features.head())\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Determining the top features using selectkbest, the higher the score the more likely they are linked\n",
    "\n",
    "best = SelectKBest(score_func=chi2, k=10)\n",
    "fit = best.fit(features, target)\n",
    "data_scores = pd.DataFrame(fit.scores_)\n",
    "data_columns = pd.DataFrame(features.columns)\n",
    "\n",
    "feature_scores = pd.concat([data_columns,data_scores],axis=1) #Putting both into a single dataframe for clarity\n",
    "feature_scores.columns = ['Feature','Score'] #Renaming columns\n",
    "\n",
    "print(feature_scores.nlargest(10,'Score')) #Printing the top 10 features descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Plotting a histogram based on the top features\n",
    "\n",
    "feature_scores = feature_scores.sort_values(by='Score', ascending=False);\n",
    "\n",
    "sns.barplot(x = 'Feature', y = 'Score', data = feature_scores)\n",
    "\n",
    "plt.box(False)\n",
    "plt.title('Feature importance', fontsize=16)\n",
    "plt.xlabel('Features', fontsize=14)\n",
    "plt.ylabel('Importance', fontsize=14)\n",
    "plt.xticks(fontsize=12, rotation=45, ha=\"right\")\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Making a list of top features\n",
    "\n",
    "feature_list = feature_scores['Feature'].tolist()[0:10]\n",
    "\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Deleting data with less correlation with CHD from original dataframe\n",
    "\n",
    "truncated_data = pd.concat([data[feature_list],data['TenYearCHD']],axis=1)\n",
    "\n",
    "print(truncated_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Seeing correlation between truncated data\n",
    "\n",
    "truncated_corr = truncated_data.corr()\n",
    "sns.heatmap(truncated_corr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Outlier detection\n",
    "\n",
    "truncated_data.describe()\n",
    "sns.pairplot(truncated_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Boxplots\n",
    "\n",
    "column_name = list(truncated_data.columns);\n",
    "\n",
    "\n",
    "for i in range(len(column_name)):\n",
    "    sns.boxplot(truncated_data['{}'.format(column_name[i])]);\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Cleaning up the dataframe\n",
    "\n",
    "def cleaning(dataframe, feature, upper):\n",
    "    \n",
    "    dataframe_original = dataframe\n",
    "    dataframe = dataframe.drop(dataframe[dataframe['{}'.format(feature)] > upper].index);\n",
    "    print('Shape: {} ---> {}'.format(dataframe_original.shape, dataframe.shape))\n",
    "    return dataframe;\n",
    "\n",
    "truncated_data = cleaning(truncated_data, 'totChol', 599);\n",
    "truncated_data = cleaning(truncated_data, 'BMI', 50);\n",
    "truncated_data = cleaning(truncated_data, 'cigsPerDay', 50);\n",
    "truncated_data = cleaning(truncated_data, 'sysBP', 250);\n",
    "print('Shape: {}' .format(truncated_data.shape));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Feature scaling\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1)) \n",
    "scaled_data = pd.DataFrame(scaler.fit_transform(truncated_data), columns=truncated_data.columns)\n",
    "\n",
    "print(scaled_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test\n",
    "y = scaled_data.iloc[:,-1]\n",
    "x = scaled_data.iloc[:,:-1]\n",
    "\n",
    "print(y.head())\n",
    "print(x.head())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=1)\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Resampling dataset\n",
    "target_count = scaled_data.TenYearCHD.value_counts()\n",
    "\n",
    "print(target_count[0])\n",
    "print(target_count[1])\n",
    "print(round(target_count[0] / target_count[1], 2), ': 1')\n",
    "\n",
    "sns.countplot(scaled_data.TenYearCHD)\n",
    "plt.box(False)\n",
    "plt.xlabel('Heart Disease No/Yes',fontsize=11)\n",
    "plt.ylabel('Patient Count',fontsize=11)\n",
    "plt.title('Count Outcome Heart Disease\\n')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = scaled_data.sample(frac=1,random_state=1)\n",
    "\n",
    "CHD_data = shuffled_data.loc[shuffled_data['TenYearCHD'] == 1]\n",
    "non_CHD_data = shuffled_data.loc[shuffled_data['TenYearCHD'] == 0].sample(n=target_count[1], random_state = 1)\n",
    "\n",
    "print(CHD_data.shape)\n",
    "print(non_CHD_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_data = pd.concat([CHD_data, non_CHD_data])\n",
    "normalised_data.TenYearCHD.value_counts()\n",
    "\n",
    "normalised_target_count = normalised_data.TenYearCHD.value_counts()\n",
    "\n",
    "sns.countplot(normalised_data.TenYearCHD)\n",
    "print(round(normalised_target_count[0] / normalised_target_count[1], 2), ': 1')\n",
    "plt.box(False)\n",
    "plt.xlabel('Heart Disease No/Yes',fontsize=11)\n",
    "plt.ylabel('Patient Count',fontsize=11)\n",
    "plt.title('Count Outcome Heart Disease\\n')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = normalised_data.iloc[:,-1]\n",
    "x_train = normalised_data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(model, y_test, pred):\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score (y_test, pred)\n",
    "    \n",
    "    print(\"The accuracy score for {} is: {}%.\".format(model, round(accuracy,3)*100))\n",
    "    print(\"The f1 score for {} is: {}%.\".format(model, round(f1,3)*100))\n",
    "    print(\"The precision score for {} is: {}%.\".format(model, round(precision,3)*100))\n",
    "    print(\"The recall score for {} is: {}%.\".format(model, round(recall,3)*100))\n",
    "    \n",
    "    return(accuracy, f1, precision, recall)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(dataframe, name):\n",
    "    sns.heatmap(pd.DataFrame(dataframe), annot=True , fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.title('Confusion matrix {}\\n'.format(name), y=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(classifier, name):\n",
    "    classifier.fit(x_train, y_train);\n",
    "    classifier_pred = classifier.predict(x_test);\n",
    "    confusion(confusion_matrix(y_test, classifier_pred), name);\n",
    "    scores(name, y_test, classifier_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier();\n",
    "model(dtc, 'Decision Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators= 100,bootstrap = True, max_features = 'sqrt');\n",
    "model(rfc, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the preprocessing module for the Exeter NatSci Machine Learning Group.....\n",
      "Successfully imported the preprocessing module\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_ml import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(scale_data(drop_missing(chose_features(pd.read_csv(\"framingham.csv\")))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (<ipython-input-61-6678925b16d7>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-61-6678925b16d7>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    return(accuracy, f1, precision, recall);\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "def scores(name, y_test, pred, display):\n",
    "    accuracy = accuracy_score(y_test, pred);\n",
    "    f1 = f1_score(y_test, pred);\n",
    "    precision = precision_score(y_test, pred);\n",
    "    recall = recall_score(y_test, pred);\n",
    "    \n",
    "    if display == 'yes':\n",
    "        print(\"The accuracy score for {} is: {}%.\".format(name, round(accuracy, 3) * 100))\n",
    "        print(\"The f1 score for {} is: {}%.\".format(name, round(f1, 3) * 100))\n",
    "        print(\"The precision score for {} is: {}%.\".format(name, round(precision, 3) * 100))\n",
    "        print(\"The recall score for {} is: {}%.\".format(name, round(recall, 3) * 100))\n",
    "    else:\n",
    "        \n",
    "    \n",
    "\n",
    "    return(accuracy, f1, precision, recall);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(classifier, name, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train);\n",
    "    classifier_pred = classifier.predict(X_test);\n",
    "    score = scores(name, y_test, classifier_pred, no);\n",
    "    \n",
    "    accuracy = score[0];\n",
    "    f1 = score[1];\n",
    "    precision = score[2];\n",
    "    recall = score[3];\n",
    "    \n",
    "    return(accuracy, f1, precision, recall);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'no' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-afb4464d0058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Decision Tree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-eb94a1733870>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(classifier, name, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mclassifier_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'no' is not defined"
     ]
    }
   ],
   "source": [
    "model(DecisionTreeClassifier(), 'Decision Tree', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 19.7%.\n",
      "The precision score for Random Forest is: 51.7%.\n",
      "The recall score for Random Forest is: 12.2%.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8333333333333334,\n",
       " 0.19736842105263158,\n",
       " 0.5172413793103449,\n",
       " 0.12195121951219512)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(RandomForestClassifier(n_estimators=10, bootstrap=True, max_features='sqrt'), 'Random Forest', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Random Forest is: 82.8%.\n",
      "The f1 score for Random Forest is: 11.3%.\n",
      "The precision score for Random Forest is: 42.1%.\n",
      "The recall score for Random Forest is: 6.5%.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8278688524590164"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 100\n",
    "\n",
    "model(RandomForestClassifier(n_estimators=i, bootstrap=True, max_features='sqrt'), 'Random Forest', X_train, X_test, y_train, y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.\n",
      "  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.\n",
      "  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.\n",
      "  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.\n",
      "  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.\n",
      "  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.  98.\n",
      "  99. 100.]\n",
      "The accuracy score for Random Forest is: 74.5%.\n",
      "The f1 score for Random Forest is: 22.400000000000002%.\n",
      "The precision score for Random Forest is: 22.900000000000002%.\n",
      "The recall score for Random Forest is: 22.0%.\n",
      "The accuracy score for Random Forest is: 81.69999999999999%.\n",
      "The f1 score for Random Forest is: 11.799999999999999%.\n",
      "The precision score for Random Forest is: 31.0%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 80.10000000000001%.\n",
      "The f1 score for Random Forest is: 19.8%.\n",
      "The precision score for Random Forest is: 30.5%.\n",
      "The recall score for Random Forest is: 14.6%.\n",
      "The accuracy score for Random Forest is: 82.0%.\n",
      "The f1 score for Random Forest is: 14.299999999999999%.\n",
      "The precision score for Random Forest is: 35.5%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 81.6%.\n",
      "The f1 score for Random Forest is: 22.0%.\n",
      "The precision score for Random Forest is: 38.0%.\n",
      "The recall score for Random Forest is: 15.4%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 15.1%.\n",
      "The precision score for Random Forest is: 47.8%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 23.799999999999997%.\n",
      "The precision score for Random Forest is: 51.4%.\n",
      "The recall score for Random Forest is: 15.4%.\n",
      "The accuracy score for Random Forest is: 82.89999999999999%.\n",
      "The f1 score for Random Forest is: 8.799999999999999%.\n",
      "The precision score for Random Forest is: 42.9%.\n",
      "The recall score for Random Forest is: 4.9%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 19.5%.\n",
      "The precision score for Random Forest is: 48.4%.\n",
      "The recall score for Random Forest is: 12.2%.\n",
      "The accuracy score for Random Forest is: 82.8%.\n",
      "The f1 score for Random Forest is: 10.0%.\n",
      "The precision score for Random Forest is: 41.199999999999996%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 82.89999999999999%.\n",
      "The f1 score for Random Forest is: 20.4%.\n",
      "The precision score for Random Forest is: 47.099999999999994%.\n",
      "The recall score for Random Forest is: 13.0%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 17.599999999999998%.\n",
      "The precision score for Random Forest is: 52.0%.\n",
      "The recall score for Random Forest is: 10.6%.\n",
      "The accuracy score for Random Forest is: 82.39999999999999%.\n",
      "The f1 score for Random Forest is: 17.8%.\n",
      "The precision score for Random Forest is: 41.199999999999996%.\n",
      "The recall score for Random Forest is: 11.4%.\n",
      "The accuracy score for Random Forest is: 83.7%.\n",
      "The f1 score for Random Forest is: 16.8%.\n",
      "The precision score for Random Forest is: 60.0%.\n",
      "The recall score for Random Forest is: 9.8%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 16.400000000000002%.\n",
      "The precision score for Random Forest is: 52.2%.\n",
      "The recall score for Random Forest is: 9.8%.\n",
      "The accuracy score for Random Forest is: 83.7%.\n",
      "The f1 score for Random Forest is: 16.8%.\n",
      "The precision score for Random Forest is: 60.0%.\n",
      "The recall score for Random Forest is: 9.8%.\n",
      "The accuracy score for Random Forest is: 82.89999999999999%.\n",
      "The f1 score for Random Forest is: 15.0%.\n",
      "The precision score for Random Forest is: 45.800000000000004%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 82.39999999999999%.\n",
      "The f1 score for Random Forest is: 7.199999999999999%.\n",
      "The precision score for Random Forest is: 31.2%.\n",
      "The recall score for Random Forest is: 4.1000000000000005%.\n",
      "The accuracy score for Random Forest is: 82.8%.\n",
      "The f1 score for Random Forest is: 11.3%.\n",
      "The precision score for Random Forest is: 42.1%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 82.39999999999999%.\n",
      "The f1 score for Random Forest is: 9.8%.\n",
      "The precision score for Random Forest is: 35.0%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 82.5%.\n",
      "The f1 score for Random Forest is: 15.8%.\n",
      "The precision score for Random Forest is: 41.4%.\n",
      "The recall score for Random Forest is: 9.8%.\n",
      "The accuracy score for Random Forest is: 82.8%.\n",
      "The f1 score for Random Forest is: 11.3%.\n",
      "The precision score for Random Forest is: 42.1%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 82.69999999999999%.\n",
      "The f1 score for Random Forest is: 17.0%.\n",
      "The precision score for Random Forest is: 43.3%.\n",
      "The recall score for Random Forest is: 10.6%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 10.100000000000001%.\n",
      "The precision score for Random Forest is: 46.7%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 82.69999999999999%.\n",
      "The f1 score for Random Forest is: 12.4%.\n",
      "The precision score for Random Forest is: 40.9%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 82.39999999999999%.\n",
      "The f1 score for Random Forest is: 9.8%.\n",
      "The precision score for Random Forest is: 35.0%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 14.099999999999998%.\n",
      "The precision score for Random Forest is: 52.6%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 82.89999999999999%.\n",
      "The f1 score for Random Forest is: 13.8%.\n",
      "The precision score for Random Forest is: 45.5%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 15.299999999999999%.\n",
      "The precision score for Random Forest is: 52.400000000000006%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 13.900000000000002%.\n",
      "The precision score for Random Forest is: 47.599999999999994%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 82.89999999999999%.\n",
      "The f1 score for Random Forest is: 13.8%.\n",
      "The precision score for Random Forest is: 45.5%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 14.2%.\n",
      "The precision score for Random Forest is: 55.60000000000001%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 13.900000000000002%.\n",
      "The precision score for Random Forest is: 47.599999999999994%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 82.69999999999999%.\n",
      "The f1 score for Random Forest is: 14.799999999999999%.\n",
      "The precision score for Random Forest is: 42.3%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 16.400000000000002%.\n",
      "The precision score for Random Forest is: 52.2%.\n",
      "The recall score for Random Forest is: 9.8%.\n",
      "The accuracy score for Random Forest is: 82.89999999999999%.\n",
      "The f1 score for Random Forest is: 13.8%.\n",
      "The precision score for Random Forest is: 45.5%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 83.6%.\n",
      "The f1 score for Random Forest is: 16.7%.\n",
      "The precision score for Random Forest is: 57.099999999999994%.\n",
      "The recall score for Random Forest is: 9.8%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 10.299999999999999%.\n",
      "The precision score for Random Forest is: 53.800000000000004%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 15.299999999999999%.\n",
      "The precision score for Random Forest is: 52.400000000000006%.\n",
      "The recall score for Random Forest is: 8.9%.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Random Forest is: 83.2%.\n",
      "The f1 score for Random Forest is: 7.5%.\n",
      "The precision score for Random Forest is: 50.0%.\n",
      "The recall score for Random Forest is: 4.1000000000000005%.\n",
      "The accuracy score for Random Forest is: 82.89999999999999%.\n",
      "The f1 score for Random Forest is: 15.0%.\n",
      "The precision score for Random Forest is: 45.800000000000004%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 83.89999999999999%.\n",
      "The f1 score for Random Forest is: 16.900000000000002%.\n",
      "The precision score for Random Forest is: 63.2%.\n",
      "The recall score for Random Forest is: 9.8%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 15.4%.\n",
      "The precision score for Random Forest is: 55.00000000000001%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 83.6%.\n",
      "The f1 score for Random Forest is: 14.299999999999999%.\n",
      "The precision score for Random Forest is: 58.8%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 82.69999999999999%.\n",
      "The f1 score for Random Forest is: 12.4%.\n",
      "The precision score for Random Forest is: 40.9%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 12.7%.\n",
      "The precision score for Random Forest is: 47.4%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 82.39999999999999%.\n",
      "The f1 score for Random Forest is: 8.5%.\n",
      "The precision score for Random Forest is: 33.300000000000004%.\n",
      "The recall score for Random Forest is: 4.9%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 11.4%.\n",
      "The precision score for Random Forest is: 47.099999999999994%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 12.9%.\n",
      "The precision score for Random Forest is: 56.2%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 83.2%.\n",
      "The f1 score for Random Forest is: 10.2%.\n",
      "The precision score for Random Forest is: 50.0%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 82.89999999999999%.\n",
      "The f1 score for Random Forest is: 16.1%.\n",
      "The precision score for Random Forest is: 46.2%.\n",
      "The recall score for Random Forest is: 9.8%.\n",
      "The accuracy score for Random Forest is: 82.69999999999999%.\n",
      "The f1 score for Random Forest is: 8.6%.\n",
      "The precision score for Random Forest is: 37.5%.\n",
      "The recall score for Random Forest is: 4.9%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 12.9%.\n",
      "The precision score for Random Forest is: 56.2%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 83.6%.\n",
      "The f1 score for Random Forest is: 14.299999999999999%.\n",
      "The precision score for Random Forest is: 58.8%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 13.900000000000002%.\n",
      "The precision score for Random Forest is: 47.599999999999994%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 10.100000000000001%.\n",
      "The precision score for Random Forest is: 46.7%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 11.700000000000001%.\n",
      "The precision score for Random Forest is: 57.099999999999994%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 13.900000000000002%.\n",
      "The precision score for Random Forest is: 47.599999999999994%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 82.8%.\n",
      "The f1 score for Random Forest is: 16.0%.\n",
      "The precision score for Random Forest is: 44.4%.\n",
      "The recall score for Random Forest is: 9.8%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 15.299999999999999%.\n",
      "The precision score for Random Forest is: 52.400000000000006%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 83.6%.\n",
      "The f1 score for Random Forest is: 15.5%.\n",
      "The precision score for Random Forest is: 57.9%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 15.4%.\n",
      "The precision score for Random Forest is: 55.00000000000001%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 83.7%.\n",
      "The f1 score for Random Forest is: 17.9%.\n",
      "The precision score for Random Forest is: 59.099999999999994%.\n",
      "The recall score for Random Forest is: 10.6%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 11.4%.\n",
      "The precision score for Random Forest is: 47.099999999999994%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 16.6%.\n",
      "The precision score for Random Forest is: 54.50000000000001%.\n",
      "The recall score for Random Forest is: 9.8%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 10.4%.\n",
      "The precision score for Random Forest is: 58.3%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 83.2%.\n",
      "The f1 score for Random Forest is: 15.2%.\n",
      "The precision score for Random Forest is: 50.0%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 82.8%.\n",
      "The f1 score for Random Forest is: 11.3%.\n",
      "The precision score for Random Forest is: 42.1%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 14.2%.\n",
      "The precision score for Random Forest is: 55.60000000000001%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 83.2%.\n",
      "The f1 score for Random Forest is: 11.5%.\n",
      "The precision score for Random Forest is: 50.0%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 82.8%.\n",
      "The f1 score for Random Forest is: 10.0%.\n",
      "The precision score for Random Forest is: 41.199999999999996%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 11.700000000000001%.\n",
      "The precision score for Random Forest is: 57.099999999999994%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 84.3%.\n",
      "The f1 score for Random Forest is: 19.6%.\n",
      "The precision score for Random Forest is: 70.0%.\n",
      "The recall score for Random Forest is: 11.4%.\n",
      "The accuracy score for Random Forest is: 84.0%.\n",
      "The f1 score for Random Forest is: 18.2%.\n",
      "The precision score for Random Forest is: 65.0%.\n",
      "The recall score for Random Forest is: 10.6%.\n",
      "The accuracy score for Random Forest is: 82.89999999999999%.\n",
      "The f1 score for Random Forest is: 13.8%.\n",
      "The precision score for Random Forest is: 45.5%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 82.8%.\n",
      "The f1 score for Random Forest is: 8.7%.\n",
      "The precision score for Random Forest is: 40.0%.\n",
      "The recall score for Random Forest is: 4.9%.\n",
      "The accuracy score for Random Forest is: 82.8%.\n",
      "The f1 score for Random Forest is: 12.5%.\n",
      "The precision score for Random Forest is: 42.9%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 12.9%.\n",
      "The precision score for Random Forest is: 56.2%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 83.7%.\n",
      "The f1 score for Random Forest is: 15.6%.\n",
      "The precision score for Random Forest is: 61.1%.\n",
      "The recall score for Random Forest is: 8.9%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 13.900000000000002%.\n",
      "The precision score for Random Forest is: 47.599999999999994%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 82.89999999999999%.\n",
      "The f1 score for Random Forest is: 10.100000000000001%.\n",
      "The precision score for Random Forest is: 43.8%.\n",
      "The recall score for Random Forest is: 5.7%.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 11.600000000000001%.\n",
      "The precision score for Random Forest is: 53.300000000000004%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 14.099999999999998%.\n",
      "The precision score for Random Forest is: 52.6%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 82.8%.\n",
      "The f1 score for Random Forest is: 10.0%.\n",
      "The precision score for Random Forest is: 41.199999999999996%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 10.299999999999999%.\n",
      "The precision score for Random Forest is: 53.800000000000004%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 12.7%.\n",
      "The precision score for Random Forest is: 47.4%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 12.9%.\n",
      "The precision score for Random Forest is: 52.900000000000006%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 8.799999999999999%.\n",
      "The precision score for Random Forest is: 46.2%.\n",
      "The recall score for Random Forest is: 4.9%.\n",
      "The accuracy score for Random Forest is: 83.2%.\n",
      "The f1 score for Random Forest is: 12.8%.\n",
      "The precision score for Random Forest is: 50.0%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 14.099999999999998%.\n",
      "The precision score for Random Forest is: 52.6%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 14.2%.\n",
      "The precision score for Random Forest is: 55.60000000000001%.\n",
      "The recall score for Random Forest is: 8.1%.\n",
      "The accuracy score for Random Forest is: 82.5%.\n",
      "The f1 score for Random Forest is: 8.6%.\n",
      "The precision score for Random Forest is: 35.3%.\n",
      "The recall score for Random Forest is: 4.9%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 11.4%.\n",
      "The precision score for Random Forest is: 47.099999999999994%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 83.1%.\n",
      "The f1 score for Random Forest is: 10.100000000000001%.\n",
      "The precision score for Random Forest is: 46.7%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 83.5%.\n",
      "The f1 score for Random Forest is: 12.9%.\n",
      "The precision score for Random Forest is: 56.2%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 83.2%.\n",
      "The f1 score for Random Forest is: 12.8%.\n",
      "The precision score for Random Forest is: 50.0%.\n",
      "The recall score for Random Forest is: 7.3%.\n",
      "The accuracy score for Random Forest is: 83.2%.\n",
      "The f1 score for Random Forest is: 10.2%.\n",
      "The precision score for Random Forest is: 50.0%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "The accuracy score for Random Forest is: 82.8%.\n",
      "The f1 score for Random Forest is: 11.3%.\n",
      "The precision score for Random Forest is: 42.1%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 11.600000000000001%.\n",
      "The precision score for Random Forest is: 53.300000000000004%.\n",
      "The recall score for Random Forest is: 6.5%.\n",
      "The accuracy score for Random Forest is: 83.3%.\n",
      "The f1 score for Random Forest is: 10.299999999999999%.\n",
      "The precision score for Random Forest is: 53.800000000000004%.\n",
      "The recall score for Random Forest is: 5.7%.\n",
      "[0.744535519125683, 0.8169398907103825, 0.8005464480874317, 0.819672131147541, 0.8155737704918032, 0.8306010928961749, 0.8333333333333334, 0.8292349726775956, 0.8306010928961749, 0.8278688524590164, 0.8292349726775956, 0.8333333333333334, 0.8237704918032787, 0.837431693989071, 0.8333333333333334, 0.837431693989071, 0.8292349726775956, 0.8237704918032787, 0.8278688524590164, 0.8237704918032787, 0.825136612021858, 0.8278688524590164, 0.8265027322404371, 0.8306010928961749, 0.8265027322404371, 0.8237704918032787, 0.8333333333333334, 0.8292349726775956, 0.8333333333333334, 0.8306010928961749, 0.8292349726775956, 0.8346994535519126, 0.8306010928961749, 0.8265027322404371, 0.8333333333333334, 0.8292349726775956, 0.8360655737704918, 0.8333333333333334, 0.8333333333333334, 0.8319672131147541, 0.8292349726775956, 0.8387978142076503, 0.8346994535519126, 0.8360655737704918, 0.8265027322404371, 0.8306010928961749, 0.8237704918032787, 0.8306010928961749, 0.8346994535519126, 0.8319672131147541, 0.8292349726775956, 0.8265027322404371, 0.8346994535519126, 0.8360655737704918, 0.8306010928961749, 0.8306010928961749, 0.8346994535519126, 0.8306010928961749, 0.8278688524590164, 0.8333333333333334, 0.8360655737704918, 0.8346994535519126, 0.837431693989071, 0.8306010928961749, 0.8346994535519126, 0.8346994535519126, 0.8319672131147541, 0.8278688524590164, 0.8346994535519126, 0.8319672131147541, 0.8278688524590164, 0.8346994535519126, 0.842896174863388, 0.8401639344262295, 0.8292349726775956, 0.8278688524590164, 0.8278688524590164, 0.8346994535519126, 0.837431693989071, 0.8306010928961749, 0.8292349726775956, 0.8333333333333334, 0.8333333333333334, 0.8278688524590164, 0.8333333333333334, 0.8306010928961749, 0.8333333333333334, 0.8306010928961749, 0.8319672131147541, 0.8333333333333334, 0.8346994535519126, 0.825136612021858, 0.8306010928961749, 0.8306010928961749, 0.8346994535519126, 0.8319672131147541, 0.8319672131147541, 0.8278688524590164, 0.8333333333333334, 0.8333333333333334]\n"
     ]
    }
   ],
   "source": [
    "y = np.linspace(1,100,100);\n",
    "#y = np.int(y)\n",
    "print(y)\n",
    "accuracy_list = []\n",
    "for i in range(len(y)):\n",
    "    accuracy_list.append(model(RandomForestClassifier(n_estimators=i+1, bootstrap=True, max_features='sqrt'), 'Random Forest', X_train, X_test, y_train, y_test)[0]);\n",
    "    \n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
